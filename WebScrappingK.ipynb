{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROGRAM:\n",
    "\n",
    "ALGORITHM:\n",
    "\n",
    "1.Get the list of Most actives, Gainers and Losers from the given CNN website using Beautiful Soup and urllib.\n",
    "\n",
    "2.Create lists to store all the actives, gainers and losers and another list to store individual ticker info.\n",
    "\n",
    "3.Using the Beautiful Soup individually call all the categories from the CNN website and print.\n",
    "\n",
    "4.Using the stock information page collect ticker symbol data from all categories and build a csv file.\n",
    "\n",
    "5.Ask you User input to choose a company to get the data.\n",
    "\n",
    "6.Print all the individual company data like Open, Prev Close, Volume, Market Cap of user interest.\n",
    "\n",
    "\n",
    "\n",
    "INSTRUCTION TO EXECUTE THE CODE:\n",
    "\n",
    "After running the code all the most actives, Gainers, Loser are printed to the user.Now, Input box is promted for the user input  to choose a company to get the data of user company of interest. After the user chooses his company of interest the data collected from the website like the OPEN Price, PREV CLOSE price, VOLUME, Market cap is displayed to the user.\n",
    "\n",
    "\n",
    "\n",
    "EXPECTED OUTPUT:\n",
    "\n",
    "\n",
    " Most Actives:\n",
    "GE General Electric Co\n",
    "PFE Pfizer Inc\n",
    "T AT&T Inc\n",
    "F Ford Motor Co\n",
    "CCL Carnival Corp\n",
    "MRO Marathon Oil Corp\n",
    "BAC Bank of America Corp\n",
    "OXY Occidental Petroleum Corp\n",
    "XOM Exxon Mobil Corp\n",
    "WFC Wells Fargo & Co\n",
    "\n",
    "\n",
    " Gainers:\n",
    "EFX Equifax Inc\n",
    "NCLH Norwegian Cruise Line Holdings Ltd\n",
    "MRO Marathon Oil Corp\n",
    "OXY Occidental Petroleum Corp\n",
    "LUMN Centurylink Inc\n",
    "HAL Halliburton Co\n",
    "T AT&T Inc\n",
    "PXD Pioneer Natural Resources Co\n",
    "XOM Exxon Mobil Corp\n",
    "MTD Mettler-Toledo International Inc\n",
    "\n",
    "\n",
    " Losers:\n",
    "AZO Autozone Inc\n",
    "LEN Lennar Corp\n",
    "DHI D.R. Horton Inc\n",
    "LEG Leggett & Platt Inc\n",
    "PHM Pultegroup Inc\n",
    "NI NiSource Inc\n",
    "CNP CenterPoint Energy Inc\n",
    "WHR Whirlpool Corp\n",
    "FLT Fleetcor Technologies Inc\n",
    "AVB Avalonbay Communities Inc\n",
    "User inputs to choose the company of interest:COTY\n",
    "\n",
    "The data for COTY Coty Inc (NYSE:COTY)is the following:\n",
    "\n",
    "Coty Inc (NYSE:COTY)\n",
    "OPEN: 7.20\n",
    "PREV CLOSE: 7.45\n",
    "VOLUME: 15,791,831\n",
    "MARKET CAP: $5.9B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request,urllib.parse,urllib.error\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "#Navigablestring-holds text within HTML, provides methods for searching and navigation\n",
    "\n",
    "import ssl\n",
    "import re\n",
    " \n",
    "#store opening price and closing file info in csv/textfile\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most Actives:\n",
      "PFE Pfizer Inc\n",
      "F Ford Motor Co\n",
      "GM General Motors Co\n",
      "BAC Bank of America Corp\n",
      "CCL Carnival Corp\n",
      "T AT&T Inc\n",
      "XOM Exxon Mobil Corp\n",
      "OXY Occidental Petroleum Corp\n",
      "NCLH Norwegian Cruise Line Holdings Ltd\n",
      "FCX Freeport-McMoRan Inc\n",
      "\n",
      "\n",
      " Gainers:\n",
      "OXY Occidental Petroleum Corp\n",
      "DVN Devon Energy Corp\n",
      "MRO Marathon Oil Corp\n",
      "EOG EOG Resources Inc\n",
      "HAL Halliburton Co\n",
      "HES Hess Corp\n",
      "BKR Baker Hughes Co\n",
      "ALB Albemarle Corp\n",
      "COP Conocophillips\n",
      "XOM Exxon Mobil Corp\n",
      "\n",
      "\n",
      " Losers:\n",
      "NEE Nextera Energy Inc\n",
      "LEN Lennar Corp\n",
      "AEE Ameren Corp\n",
      "PPL PPL Corp\n",
      "WEC WEC Energy Group Inc\n",
      "GM General Motors Co\n",
      "ED Consolidated Edison Inc\n",
      "PHM Pultegroup Inc\n",
      "D Dominion Energy Inc\n",
      "DUK Duke Energy Corp\n",
      "User inputs to choose the company of interest:GM\n",
      "\n",
      "The data for GM General Motors Co (NYSE:GM)is the following:\n",
      "\n",
      "General Motors Co (NYSE:GM)\n",
      "OPEN: 48.09\n",
      "PREV CLOSE: 48.80\n",
      "VOLUME: 17,355,255\n",
      "MARKET CAP: $70.8B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Extracting the CNN website information from url using the urllib\n",
    "with urllib.request.urlopen(\"https://money.cnn.com/data/hotstocks/\") as url:\n",
    "    html=url.read()\n",
    "#Using the python library for pulling the data\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "\n",
    "#Creating main_ticker_list to store all the individual ticker data\n",
    "main_ticker_list=[]\n",
    "act_name_list=[]\n",
    "act_link_list=[]\n",
    "act_title_list=[]\n",
    "MostActive_dict={}\n",
    "#Locating the Most actives on the given website and calling its data\n",
    "header=soup.find('h3',text='Most Actives')\n",
    "header_table=header.find_next_sibling('table')\n",
    "table_rows=header_table.find_all('tr')\n",
    "for tr in table_rows:\n",
    "    table_data=tr.find_all('td')\n",
    "    for td in table_data:\n",
    "        act_name=td.a.text\n",
    "#Appending all the Most actives names to the list\n",
    "        act_name_list.append(act_name)\n",
    "        act_title=td.span.get(\"title\")\n",
    "#Appending all the Most actives titles to the list\n",
    "        act_title_list.append(act_title)\n",
    "        act_link=td.a.get(\"href\")\n",
    "        ticker_list=[]\n",
    "        ticker_list.append(\"Most Actives\")\n",
    "        ticker_list.append(act_name)\n",
    "        ticker_list.append(act_title)\n",
    "#Extracting the individual ticker company data of Most Actives from the website\n",
    "        with urllib.request.urlopen(\"https://money.cnn.com/quote/quote.html?symb=\"+act_name) as url:\n",
    "            html2=url.read()\n",
    "        soup=BeautifulSoup(html2, 'lxml')\n",
    "        table_data2=soup.find('td',text=\"Today’s open\")\n",
    "        open_value=table_data2.find_next_sibling(\"td\").text\n",
    "        ticker_list.append(open_value)\n",
    "        table_data=soup.find('td',text=\"Previous close\")\n",
    "        close_value=table_data.find_next_sibling(\"td\").text\n",
    "        ticker_list.append(close_value)\n",
    "        table_data=soup.find('td',text=\"Volume\")\n",
    "        volume_value=table_data.find_next_sibling(\"td\").text\n",
    "        ticker_list.append(volume_value)\n",
    "        table_data=soup.find('td',text=\"Market cap\")\n",
    "        market_value=table_data.find_next_sibling(\"td\").text\n",
    "        ticker_list.append(market_value)\n",
    "        main_ticker_list.append(ticker_list)\n",
    "        break\n",
    "    continue\n",
    "print(\" Most Actives:\")\n",
    "newlist_mostactives={}\n",
    "#Displaying the most actives list with the company name and title\n",
    "newlist_mostactives=dict(zip(act_name_list,act_title_list))\n",
    "for key,value in newlist_mostactives.items():\n",
    "    print (key,value)   \n",
    "\n",
    "    \n",
    "with urllib.request.urlopen(\"https://money.cnn.com/data/hotstocks/\") as url:\n",
    "    html=url.read()\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "gainers_name_list=[]\n",
    "gainers_link_list=[]\n",
    "gainers_title_list=[]\n",
    "#Locating the Gainers on the given website and calling its data\n",
    "header=soup.find('h3',text='Gainers')\n",
    "header_table=header.find_next_sibling('table')\n",
    "table_rows=header_table.find_all('tr')\n",
    "for tr in table_rows:\n",
    "    table_data=tr.find_all('td')\n",
    "    for td in table_data:\n",
    "        gainers_name=td.a.text\n",
    "#Appending all the Gainers names to the list\n",
    "        gainers_name_list.append(gainers_name)\n",
    "        gainers_title=td.span.get(\"title\")\n",
    "#Appending all the Gainers titles to the list\n",
    "        gainers_title_list.append(gainers_title)\n",
    "        gainers_link=td.a.get(\"href\")\n",
    "        ticker_list_gainers=[]\n",
    "        ticker_list_gainers.append(\"Gainers\")\n",
    "        ticker_list_gainers.append(gainers_name)\n",
    "        ticker_list_gainers.append(gainers_title)\n",
    "#Extracting the individual ticker company data of Gainers from the website\n",
    "        with urllib.request.urlopen(\"https://money.cnn.com/quote/quote.html?symb=\"+gainers_name) as url:\n",
    "            html2=url.read()\n",
    "        soup=BeautifulSoup(html2, 'lxml')\n",
    "        table_data2_gainers=soup.find('td',text=\"Today’s open\")\n",
    "        open_value_gainers=table_data2_gainers.find_next_sibling(\"td\").text\n",
    "        ticker_list_gainers.append(open_value_gainers)\n",
    "        table_data_gainers=soup.find('td',text=\"Previous close\")\n",
    "        close_value_gainers=table_data_gainers.find_next_sibling(\"td\").text\n",
    "        ticker_list_gainers.append(close_value_gainers)\n",
    "        table_data_gainers=soup.find('td',text=\"Volume\")\n",
    "        volume_value_gainers=table_data_gainers.find_next_sibling(\"td\").text\n",
    "        ticker_list_gainers.append(volume_value_gainers)\n",
    "        table_data_gainers=soup.find('td',text=\"Market cap\")\n",
    "        market_value_gainers=table_data_gainers.find_next_sibling(\"td\").text\n",
    "        ticker_list_gainers.append(market_value_gainers)\n",
    "        main_ticker_list.append(ticker_list_gainers)\n",
    "        break\n",
    "    continue\n",
    "print(\"\\n\\n Gainers:\")\n",
    "newlist_gainers={}\n",
    "#Displaying the gainers list with the company name and title\n",
    "newlist_gainers=dict(zip(gainers_name_list,gainers_title_list))\n",
    "for key,value in newlist_gainers.items():\n",
    "    print (key,value)\n",
    "\n",
    "        \n",
    "with urllib.request.urlopen(\"https://money.cnn.com/data/hotstocks/\") as url:\n",
    "    html=url.read()\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "losers_name_list=[]\n",
    "losers_link_list=[]\n",
    "losers_title_list=[]\n",
    "#Locating the Losers on the given website and calling its data\n",
    "header=soup.find('h3',text='Losers')\n",
    "header_table=header.find_next_sibling('table')\n",
    "table_rows=header_table.find_all('tr')\n",
    "for tr in table_rows:\n",
    "    table_data=tr.find_all('td')\n",
    "    for td in table_data:\n",
    "        losers_name=td.a.text\n",
    "#Appending all the Losers names to the list\n",
    "        losers_name_list.append(losers_name)\n",
    "        losers_link=td.a.get(\"href\")\n",
    "        losers_link_list.append(losers_link)\n",
    "        losers_title=td.span.get(\"title\")\n",
    "#Appending all the Losers title to the list\n",
    "        losers_title_list.append(losers_title)\n",
    "        ticker_list_losers=[]\n",
    "        ticker_list_losers.append(\"Losers\")\n",
    "        ticker_list_losers.append(losers_name)\n",
    "        ticker_list_losers.append(losers_title)\n",
    "#Extracting the individual ticker company data of Losers from the website\n",
    "        with urllib.request.urlopen(\"https://money.cnn.com/quote/quote.html?symb=\"+losers_name) as url:\n",
    "            html2=url.read()\n",
    "        soup=BeautifulSoup(html2, 'lxml')\n",
    "        table_data2_losers=soup.find('td',text=\"Today’s open\")\n",
    "        open_value_losers=table_data2_losers.find_next_sibling(\"td\").text\n",
    "        ticker_list_losers.append(open_value_losers)\n",
    "        table_data_losers=soup.find('td',text=\"Previous close\")\n",
    "        close_value_losers=table_data_losers.find_next_sibling(\"td\").text\n",
    "        ticker_list_losers.append(close_value_losers)\n",
    "        table_data_losers=soup.find('td',text=\"Volume\")\n",
    "        volume_value_losers=table_data_losers.find_next_sibling(\"td\").text\n",
    "        ticker_list_losers.append(volume_value_losers)\n",
    "        table_data_losers=soup.find('td',text=\"Market cap\")\n",
    "        market_value_losers=table_data_losers.find_next_sibling(\"td\").text\n",
    "        ticker_list_losers.append(market_value_losers)\n",
    "        main_ticker_list.append(ticker_list_losers)\n",
    "        break\n",
    "    continue\n",
    "print(\"\\n\\n Losers:\")\n",
    "newlist_losers={}\n",
    "#Displaying the losers list with the company name and title\n",
    "newlist_losers=dict(zip(losers_name_list,losers_title_list))\n",
    "for key,value in newlist_losers.items():\n",
    "    print (key,value)\n",
    "\n",
    "#Opening a csv file to store all the data     \n",
    "with open('stocks.csv','w', newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "#Inserting all the list of appended company data into a csv file \n",
    "    writer.writerows(main_ticker_list)\n",
    "with open(\"stocks.csv\",newline='') as csvfile:\n",
    "    main_ticker_list=csv.reader(csvfile,delimiter=\",\")\n",
    "    \n",
    "\n",
    "    \n",
    "#User chooses company of interest\n",
    "user_inp=input(\"User inputs to choose the company of interest:\")\n",
    "#Extracting all the website data information to display individually\n",
    "with urllib.request.urlopen(\"https://money.cnn.com/quote/quote.html?symb=\"+user_inp) as url:\n",
    "    html=url.read()\n",
    "soup=BeautifulSoup(html, 'lxml')\n",
    "header=soup.find('h1').text\n",
    "print(\"\\nThe data for \"+user_inp+\" \"+header+\"is the following:\\n\")\n",
    "print(header)\n",
    "table_data=soup.find('td',text=\"Today’s open\")\n",
    "open_value=table_data.find_next_sibling(\"td\").text\n",
    "print(\"OPEN: \"+open_value)\n",
    "table_data=soup.find('td',text=\"Previous close\")\n",
    "close_value=table_data.find_next_sibling(\"td\").text\n",
    "print(\"PREV CLOSE: \"+close_value)\n",
    "table_data=soup.find('td',text=\"Volume\")\n",
    "volume_value=table_data.find_next_sibling(\"td\").text\n",
    "print(\"VOLUME: \"+volume_value)\n",
    "table_data=soup.find('td',text=\"Market cap\")\n",
    "market_value=table_data.find_next_sibling(\"td\").text\n",
    "print(\"MARKET CAP: \"+market_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
